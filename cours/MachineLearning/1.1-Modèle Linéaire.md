
# <span class="h1">Modèle Linéaire</span>
#cours #MachineLearning 


> [!summary] 
> *Un modèle linéaire en machine learning est une méthode simple et efficace pour prédire des valeurs numériques ou classifier des données. Il repose sur l'hypothèse que la relation entre les entrées et la sortie peut être représentée par une ligne droite (en deux dimensions) ou un hyperplan (en dimensions supérieurs) *


## <span class="h2">Concept de base</span>

> [!info] 
> Un modèle linéaire est défini par une formule qui prend plusieurs paramètres en entrée et les transforme en une sortie prédictive. La formule générale d'un modèle linéaire est 
$$y=w0​+w1​x1​+w2​x2​+⋯+wn​xn$$ 


- <u>Les entrées</u> ($x_i$) : Les entrées, ou caractéristiques (features), sont les variables indépendantes utilisées pour faire des prédictions. Chaque entrée $x_î$ représente une caractéristique particulière d'une observation.
	- <u>Exemple :</u> Dans un modèle prédisant le prix des maisons, les entrées pourraient inclure la surface de la maison, le nombre de chambres, l'année de construction, etc.

-  <u>La sortie</u> ($y$) :La sortie est la variable dépendante que le modèle essaie de prédire.

- <u>Les poids</u> ($w_i$) : Les poids sont les coefficients qui multiplient chaque entrée dans l'équation du modèle linéaire. Ils déterminent l'importance de chaque caractéristique pour la prédiction finale.
	- <u>Exemple :</u> Si une maison a une surface de 70 m² et le poids pour la surface est 2, alors la contribution de la surface à la prédiction du prix serait $70 \times 2 = 140$

- <u>Le biais</u> ($w_0$) : Le biais est une constante ajoutée au modèle pour ajuster la prédiction indépendamment des entrées. Il permet de décaler la ligne de régression vers le haut ou vers le bas.
	- <u>Exemple</u>: Si le biais est 30, cela signifie que même si toutes les entrées étaient égales à zéro, la prédiction de base commencerait à 30.
 




## <span class="h2">Les hyperparamètres</span>

> [!summary] 
> *Les hyperparamètres sont des paramètres définis avant le processus d'entraînement d'un modèle. Contrairement aux paramètres du modèle (comme les poids et les biais) qui sont appris à partir des données d'entraînement, les hyperparamètres sont configurés pour contrôler le comportement de l'algorithme d'apprentissage.* 
#### <span class="h4">Taux d'Apprentissage (Learning Rate)</span>

Le taux d'apprentissage détermine la taille des pas effectués pour mettre à jour les poids du modèle lors de l'optimisation.

- <span class="bold">Valeur élevée :</span> Converge plus rapidement mais peut dépasser le minimum de la fonction de coût.
- <span class="bold">Valeur faible :</span> Converge plus lentement mais est plus précise et stable.


#### <span class="h4">Nombre d'Itérations (Epoch)</span>

Le nombre d'itérations est le nombre de fois que l'algorithme parcourt l'ensemble de données d'entraînement.

- <span class="bold">Plus d'itérations : </span> Peut améliorer l'entraînement mais peut entraîner un surapprentissage si trop nombreuses.
- <span class="bold">Moins d'itérations:</span> Peut entraîner un sous-apprentissage si insuffisantes.


#### <span class="h4">Taille du Batch (Batch)</span>

La taille du batch est le nombre d'exemples de données utilisés pour calculer l'erreur et mettre à jour les poids à chaque itération.

- <span class="bold">Batch size = 1 :</span> Apprentissage en ligne (ou stochastique), plus de bruit mais peut trouver de meilleurs minima.
- <span class="bold">Batch size = totalité des données :</span> Apprentissage par batch complet, moins de bruit mais peut être moins efficace.
- <span class="bold">Batch size intermédiaire:**</span> Compromis entre les deux, souvent utilisé dans la pratique.

#### <span class="h4">Fonction d'activation</span>

Les fonctions d'activation sont essentielles dans les réseaux de neurones car elles introduisent de la non linéarité dans le modèle




## <span class="h2">Fonctions de Coût (Loss)</span>

> [!summary] 
> Les fonctions de coût, ou fonctions de perte, mesurent la performance d'un modèle de machine learning en quantifiant l'erreur entre les prédictions du modèle et les valeurs réelles des données. Dans les modèles linéaires, ces fonctions jouent un rôle crucial pour guider l'optimisation des paramètres du modèle. 


#### <span class="h4">Erreur Quadratique Moyenne (MSE - Mean Squared Error)</span>

L'Erreur Quadratique Moyenne est la fonction de coût la plus couramment utilisée pour la régression. Elle mesure la moyenne des carrés des différences entre les valeurs prédites et les valeurs réelles.

$$MSE=\frac1𝑚∑_ {𝑖=1}^𝑚(𝑦'_𝑖−𝑦_𝑖)^2$$
- $𝑦'_𝑖​$ est la valeur prédite par le modèle.
- $y_i​$ est la valeur réelle.
- $m$ est le nombre total d'observations.

<u>Avantages :</u>

- Punir davantage les grands écarts grâce au carré de la différence, ce qui peut aider à obtenir un modèle plus précis.

<u>Inconvénients :</u>

- Peut être excessivement affectée par les valeurs aberrantes (outliers) en raison du carré des différences.



#### <span class="h4">Erreur Absolue Moyenne (MAE - Mean Absolute Error) </span>

L'Erreur Absolue Moyenne mesure la moyenne des valeurs absolues des différences entre les prédictions et les valeurs réelles. C'est une alternative au MSE.

$$MAE=1𝑚∑𝑖=1𝑚∣𝑦^𝑖−𝑦𝑖∣$$
- $𝑦'_𝑖​$ est la valeur prédite par le modèle.
- $y_i​$ est la valeur réelle.
- $m$ est le nombre total d'observations.

<u>Avantages :</u>

- Moins sensible aux valeurs aberrantes par rapport au MSE.

<u>Inconvénients :</u>

- Moins lisse que le MSE, ce qui peut rendre l'optimisation des paramètres plus difficile car la dérivée de la valeur absolue n'est pas définie à zéro.


### <span class="h3">Conclusion</span>

Le modèle linéaire est une méthode fondamentale en machine learning pour faire des prédictions. En comprenant les concepts de biais, poids, fonction de coût et gradient descent, nous pouvons ajuster notre modèle pour minimiser les erreurs et améliorer les prédictions.
