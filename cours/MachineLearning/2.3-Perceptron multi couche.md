# <span class="h1">Perceptron Multi Couche (MLP)</span>
#cours #MachineLearning 


> [!summary] 
> *Un perceptron multi-couches (PMC), également connu sous le nom de réseau de neurones artificiels (ANN), est une architecture de deep learning composée de plusieurs couches de neurones organisées en série et en parallèle. Ce modèle permet de résoudre des problèmes complexes en apprenant des représentations hiérarchiques des données.* 

## <span class="h2">Principes de Fonctionnement</span>

> [!info] 
> Chaque neurone effectue une somme pondérée de ses entrées et applique une fonction d'activation non linéaire pour produire une sortie. L'apprentissage dans un MLP se fait par rétropropagation, où l'erreur entre les prédictions du modèle et les résultats attendus est utilisée pour ajuster les poids et les biais des neurones. Ce processus permet au MLP de modéliser des relations complexes dans les données, rendant ce modèle particulièrement efficace pour des tâches de classification et de régression. 


![[mlp.excalidraw | 500]]

- <u>Couche d'Entrée :</u> Chaque neurone de cette couche correspond à une caractéristique (feature) de l'entrée.
  
- <u>Couches Cachées :</u> Effectuent la transformation des données en appliquant des poids, des biais, et des fonctions d'activation. Un PMC peut avoir plusieurs couches cachées, permettant d'apprendre des représentations de plus en plus abstraites. Chaque neurone calcule une somme pondérée de ses entrées et applique une fonction d'activation pour produire la sortie [[2.1-Fonction d'activation]]
  
- <u>Couche de Sortie :</u> Produit la prédiction finale. Le nombre de neurones dans cette couche dépend de la tâche. Un neurone pour la régression, plusieurs neurones pour la classification multi-classes. Chaque neurone calcule une somme pondérée de ses entrées et applique une fonction d'activation pour produire la sortie [[2.1-Fonction d'activation]]

- <u>Rétropropagation :</u> Pour minimiser l'erreur de prédiction, le PMC utilise l'algorithme de rétropropagation, qui ajuste les poids et les biais en fonction du gradient de l'erreur.

    - <u>Étapes de la Rétropropagation :</u>
      
        1. <u>Propagation Avant :</u> Calculer les sorties pour chaque couche jusqu'à la sortie finale.
        2. <u>Calcul de l'Erreur :</u> Comparer la sortie prédite à la sortie attendue pour calculer l'erreur.
        3. <u>Propagation Arrière :</u> Calculer les gradients de l'erreur par rapport aux poids et aux biais en remontant les couches.
        4. <u>Mise à Jour des Poids :</u> Ajuster les poids et les biais en utilisant un algorithme d'optimisation comme la descente de gradient.
           